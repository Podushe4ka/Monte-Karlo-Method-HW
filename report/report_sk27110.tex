\documentclass[a4paper,12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{geometry}
\usepackage{color}
\usepackage{caption}
\usepackage{fancyhdr}
\usepackage{titlesec}
\usepackage{setspace}
\usepackage{float}
\usepackage{booktabs}
\usepackage{multirow}

\geometry{top=2cm,bottom=2cm,left=2cm,right=2cm}

% Настройка заголовков
\titleformat{\section}{\large\bfseries\color{blue}}{}{0em}{}[\titlerule]
\titleformat{\subsection}{\bfseries\color{blue}}{}{0em}{}

% Настройка шапки и подвала
\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{Классификация распределения с помощью случайных графов}
\fancyhead[R]{\thepage}
\fancyfoot[C]{\textit{Кочетков А.В.}}

% Настройка интервала между строками
\onehalfspacing

\title{\textbf{Классификация распределения с помощью случайных графов}} 
\author{Кочетков А.В.}
\date{Дата: \today}

\begin{document}

\maketitle


\section{Используемые библиотеки и инструменты}

\begin{itemize}
    \item \texttt{networkx} -- библиотека с реализованными методами на графах
    \item \texttt{numpy, matplotlib, seaborn, pandas} -- библиотеки для визуализации и работы с данными
    \item \texttt{sklearn} -- библиотека с алгоритмами машинного обучения, в том числе алгоритмов классификации
    \item \texttt{pytest} -- библиотека для проведения тестов 
    \\
    \\
    \textbf{Файл utils.py:}
    \item \texttt{build\_knn\_nx} -- построение графа KNN с заданными параметрами по переданному списку 
    
    \item \texttt{build\_dist\_nx} -- построение дистанцированного графа с заданными параметрами по переданному списку 
    
    \item \texttt{calculate\_connected\_components} --- Вычисляет количество связных компонент графа
    \item \texttt{calculate\_chromatic\_number} --- Вычисляет хроматическое число графа (минимальное число цветов для раскраски)
    \item \texttt{calculate\_clique\_number} --- Вычисляет число клики (размер максимальной клики в графе)
    \item \texttt{calculate\_size\_maximal\_independent\_set} --- Вычисляет размер максимального независимого множества
    \item \texttt{calculate\_size\_dom\_set} --- Вычисляет размер доминирующего множества
    \item \texttt{class DataGenerator} --- Генератор случайных данных для тестирования гипотез H0 и H1.
    \item \texttt{monte\_carlo\_experiment} --- Проводит Монте-Карло эксперимент для оценки статистических свойств графов
    \item \texttt{monte\_carlo\_experiment\_for\_several\_characteristics} --- Проводит Монте-Карло эксперимент для оценки нескольких характеристик графа.
\\
    Подробное описание всех функций и классов есть в utils.py
    
    
\end{itemize}


\section{Часть 1}

\subsection{Исследуем, как ведет себя число компонент связности графа $T^{KNN}$ в зависимости от параметров построения, experiments\_1}
Зафиксируем параметры:\\
K = 4   \ \ \ \     \ \ \  \ \ \ \ \  \ \ \ \ \  \ \ \ \ \ \ \ \ \  \   # число соседей для knn\\
n\_sampels = 100  \ \ \ \ \ \ \ \ \ \ \ \   # число итераций в эксперименте Монте-Карло\\
N = 200  \ \ \ \ \ \ \ \ \ \  \ \ \ \ \ \ \ \ \ \ \ \ \ \          # размер набора генерируемых данных\\




\subsubsection*{Зависимость от параметра lambda}
Строим набор параметров lambda от 0.2 до 20 с шагом 0.2 и для каждого параметра и распределения проводим эксперимент Монте-Карло. Считаем матожидание характеристики.

\begin{center}
\includegraphics[width=10cm,keepaspectratio]{images/knn1.png} \end{center}

Как мы видим, особой зависимости от параметра lambda нет ни у одного из распределений.


\subsubsection*{Зависимость от числа соседей}

Строим набор параметров от 1 до 15 с шагом 1 и для каждого числа соседей и распределения проводим эксперимент Монте-Карло. Считаем матожидание характеристики.

\begin{center}
\includegraphics[width=10cm,keepaspectratio]{images/knn2.png} \end{center}

Для обоих распределений есть зависимость -- число компонент связности уменьшается при увеличении числа соседей. Причем для обоих распределений результаты почти идентичны.


\subsubsection*{Зависимость от размера набора данных}

Строим набор размеров данных от 10 до 1000 с шагом 10 и для каждого размера и распределения проводим эксперимент Монте-Карло. Считаем матожидание характеристики.

\begin{center}
\includegraphics[width=10cm,keepaspectratio]{images/knn3.png} \end{center}

Для обоих распределений число компонент связности растет при увеличении размера выборки, причем почти одинаково.

\subsubsection*{Выводы}
Характеристика ведет себя почти идентично для обоих распределений, поэтому использовать ее как критерий классификации -- плохая идея.

\newpage

\subsection{Исследуем, как ведет себя хроматическое число графа $T^{dist}$ в зависимости от параметров построения, experiments\_2}
\\

Зафиксируем параметры:\\
D = 0.7   \ \ \ \     \ \ \  \ \ \ \ \  \ \ \ \ \  \ \ \ \ \ \ \   # параметри dist\\
n\_sampels = 100  \ \ \ \ \ \ \ \ \ \ \ \   # число итераций в эксперименте Монте-Карло\\
N = 200  \ \ \ \ \ \ \ \ \ \  \ \ \ \ \ \ \ \ \ \ \ \ \ \          # размер набора генерируемых данных\\


Во всех пунктах делаются действия, аналогичные пунктам выше.

\subsubsection*{Зависимость от параметра lambda}

\begin{center}
\includegraphics[width=10cm,keepaspectratio]{images/dist1.png} \end{center}

Видим, что при разных распределениях характеристика ведет себя по разному при увеличении lambda (для H0 -- возрастает, для H1 -- убывает) 

\subsubsection*{Зависимость от параметра dist}

\begin{center}
\includegraphics[width=10cm,keepaspectratio]{images/dist2.png} \end{center}

Для обоих распределений характеристика возрастает, но для H1 характеристика в начале растет быстрее.

\subsubsection*{Зависимость от размера данных}

\begin{center}
\includegraphics[width=10cm,keepaspectratio]{images/dist3.png} \end{center}

Для обоих распределений характеристика возрастает, но для H1 характеристика растет быстрее.


\subsubsection*{Выводы}
При изменении параметров построения характеристики ведут себя по разному. Это говорит о том, что хроматическое число можно использовать как критерий классификации.



\subsection{Посмотрим на разделение данных и построим множество A, experiments\_3}

Зафиксируем параметры:\\
D = 0.1   \ \ \ \     \ \ \  \ \ \ \ \  \ \ \ \ \  \ \ \ \ \ \ \ \  # параметри dist\\
n\_sampels = 500  \ \ \ \ \ \ \ \ \ \ \ \   # число итераций в эксперименте Монте-Карло\\
N = 200  \ \ \ \ \ \ \ \ \ \  \ \ \ \ \ \ \ \ \ \ \ \ \ \          # размер набора генерируемых данных\\

Исходя из прошлых экспериментов, для построения множества A будем использовать дистанцированный граф, а в качестве характеристики его хроматическое число.

\subsubsection*{Посмотрим, как хорошо разделяются данные}

\begin{center}
\includegraphics[width=10cm,keepaspectratio]{images/3_1.png} \end{center}

Для выбранных параметров данные разделяются очень хорошо. 

\subsubsection*{Построим множество A}
Построим область A так, что левее ее левой границы лежит не более 5\% результатов.
При фиксированных параметрах получили, что A = $[0, 29]$.
Ошибка на H0 получилась $\leq 0.05$, полнота H1 = 1. Это очень хороший результат

\section{Часть 2}
Теперь будем работать только с дистанцированным графом. Выберем характеристики -- хроматическое число, кликовое число, размер макс. независимого множества и число доминирования. 

\subsection{Изучение характеристик для дистанцированного графа, experiments\_1}

\subsubsection*{Подберем параметр dist так, чтобы характеристики хорошо разделялись}

\begin{center}
\includegraphics[width=11cm,keepaspectratio]{images/4_1.png} \end{center}

При dist=1.5 все характеристики хорошо разделяются, будем использовать его.

\subsubsection*{Посмотрим на зависимость характеристик от размера данных}

\begin{center}
\includegraphics[width=11cm,keepaspectratio]{images/4_2.png} \end{center}

Как мы видим, все характеристики растут при увеличении n, при этом при фиксированном n для H1 каждая характеристика всегда больше, чем для H0.


\subsubsection*{Посмотрим, как хорошо разделяются наши характеристики при размерах выборки 25, 100 и 500}

\begin{center}
\includegraphics[width=13cm,keepaspectratio]{images/4_3.png} \end{center}

При данных размера 25 характеристики отделяются не очень хорошо. Зато при большом размере данных разделимость характеристик повышается.


\subsubsection*{Посмотрим на корреляцию характеристик для обоих распределений}

\begin{center}
\includegraphics[width=16cm,keepaspectratio]{images/4_4.png} \end{center}
\\
У хроматического числа и кликового числа корреляция равна 1, у размера макс. независимого множества и числа доминирования корреляция большая при обоих распределениях.\\
\\
В дальнейших экспериментах и при построении классификаторов будем исользовать только хроматические число и размер макс. независимого множества.

\subsection{Построение классификатора, experiments\_2}

Наш классификатор будет работать таким образом: по выборке строится дистанцированный граф, для него считается хроматическое число и размер максимального независимого множества, по ним и размеру выборки какой-то алгоритм классификации делает предсказание.
Пусть принятие нулевой гипотеры -- False, а первой -- True. Тогда ошибка первого рода это $FPR =\frac{FP}{FP + TN}$, 
а мощность это $Recall = \frac{TP}{TP + FN}$
\\
\textbf{Сгенерируем данные с такими колонками:}\\
Хроматическое число\\
Размер макс. независимого множества\\
Размер выборки\\
Тип распределения (0 или 1)\\
Разобьем данные на тренировочную и тестовую выборки.
\subsubsection{Обучение алгоритмов классификации}
Обучим алгоритмы KNN, LogReg и RandomForest на наших данных и сравним их метрики:
\begin{table}[h]
\centering
\caption{Сравнение метрик классификаторов}
\begin{tabular}{lccc}
\toprule
\textbf{Метрика} & \textbf{KNN} & \textbf{LogReg} & \textbf{Random Forest} \\
\midrule
FPR      & 0.0317 & 0.0312 & 0.0342 \\
Recall   & 0.9754 & 0.9546 & 0.9700 \\
Accuracy & 0.9719 & 0.9617 & 0.9679 \\
\bottomrule
\end{tabular}
\end{table}

Лучше всего работает KNN. FPR чуть лучше у LogReg, но у нее сильно хуже Recall.
Далее по обученной модели KNN построим pipeline, который будет принимать на вход уже список точек, а не список характеристик. Оценим его на выборках размера 25, 100 и 500:

\begin{table}[h]
\centering
\caption{Сравнение метрик для разных параметров}
\begin{tabular}{lccc}
\toprule
\textbf{Метрика} & \textbf{25} & \textbf{100} & \textbf{500} \\
\midrule
FPR      & 0.2550 & 0.0650 & 0.0100 \\
Recall   & 0.7050 & 0.9500 & 1.0000 \\
Accuracy & 0.7250 & 0.9425 & 0.9950 \\
\bottomrule
\end{tabular}
\section{Итого}
Были проведены эксперименты, в которых изучалась зависимость характеристик от параметра построения графа. По ним выбрались лучшие параметры построения и характеристики, которые могут являться признаками классификации. Был сгенерирован набор данных, на которых были обучены три модели классификации. На основе лучшей модели построен pipeline, который делает предсказание на основе входного списка точек.
\end{table}














\end{document}